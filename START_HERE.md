# ğŸ¯ RAG Enterprise - START HERE

## Cosa Hai Ricevuto

Una **soluzione RAG Enterprise completa, production-ready** che comprende:

```
âœ… Backend FastAPI + LangChain
âœ… Frontend Open WebUI (ChatGPT-like)
âœ… Vector Database Milvius
âœ… OCR (PaddleOCR)
âœ… Embeddings (Sentence-Transformers)
âœ… LLM (Ollama - Mistral/Llama2)
âœ… Docker Compose per deploy facile
âœ… Setup automatizzati
âœ… Documentazione completa
```

---

## ğŸ“‚ File Importanti

1. **STRUCTURE_OVERVIEW.txt** â† LEGGI QUESTO PRIMO
   - Overview della struttura
   - Comandi principali
   - Quick start scenarios

2. **STACK_FINALE.md** â† Dettagli tecnici
   - Stack tecnologico scelto
   - Hardware requirements
   - Architettura dettagliata
   - Roadmap future

3. **rag-enterprise-structure/** â† Codice vero e proprio
   - Backend Python
   - Docker files
   - Setup scripts

4. **README.md** (dentro rag-enterprise-structure)
   - Documentazione architettura

5. **QUICKSTART.md** (dentro rag-enterprise-structure)
   - Guida rapida per diversi scenari

---

## ğŸš€ Come Iniziare (3 Step)

### Step 1: Scarica/Estrai
```bash
unzip rag-enterprise-structure.zip
cd rag-enterprise-structure
```

### Step 2: Esegui Setup
```bash
# Tutto insieme (consigliato per prima volta)
chmod +x setup.sh
./setup.sh

# Oppure se preferisci modulare:
make install-all
```

### Step 3: Accedi
```
Frontend: http://localhost:3000
Backend:  http://localhost:8000
Docs:     http://localhost:8000/docs
```

---

## ğŸ“‹ Prerequisiti

**Hardware (Minimo):**
- CPU: i7/Ryzen 7 quad-core
- RAM: 32GB (64GB recommended)
- GPU: **RTX 5070 12GB** (critico per performance)
- SSD: 200GB+

**Software:**
- Docker (con NVIDIA Docker per GPU)
- Docker Compose v2+

**Sistema Operativo:**
- Linux (consigliato Ubuntu 22.04)
- macOS (con Colima/Rancher)
- Windows (WSL2 + Docker Desktop)

---

## ğŸ¯ Scenari di Deployment

### ğŸ  Scenario 1: Tutto su Una Macchina (Monolith)
```bash
./setup.sh
```
**Ideale per**: Prototipo, test, PMI

---

### ğŸ¢ Scenario 2: Backend + Frontend Separati
```
Macchina 1 (GPU potente):  Backend + DB
Macchina 2 (CPU-only):     Frontend
```
**Ideale per**: ScalabilitÃ  frontend, separazione concerns

---

### ğŸŒ Scenario 3: Multi-Location (Enterprise)
```
Datacenter 1:  Milvius DB (shared)
Datacenter 2:  Backend
Office/Remote: Frontend
```
**Ideale per**: Enterprise, HA/DR, multi-sede

---

## ğŸ”§ Comandi Utili

```bash
# Installation
make install-all          # Install everything
make install-db          # Database only
make install-backend     # Backend + Ollama
make install-frontend    # Frontend only

# Management
make logs                # Visualizza log
make stop                # Arresta
make restart             # Riavvia
make health              # Verifica salute

# Docker Compose direct
docker-compose up -d     # Avvia
docker-compose down      # Arresta
docker-compose ps        # Status
```

---

## ğŸ“Š Architettura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OPEN WEBUI (Frontend)                   â”‚
â”‚  http://localhost:3000                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ REST API
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASTAPI Backend                         â”‚
â”‚  http://localhost:8000                   â”‚
â”‚                                          â”‚
â”‚  - LangChain RAG                        â”‚
â”‚  - PaddleOCR                            â”‚
â”‚  - Embeddings (Sentence-Transformers)  â”‚
â”‚  - LLM (Ollama)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”˜
               â”‚                         â”‚
           gRPCâ”‚                         â”‚gRPC
               â”‚                         â”‚
               â†“                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MILVIUS Vector Database                â”‚
â”‚  TCP 19530 (gRPC), HTTP 9091           â”‚
â”‚                                         â”‚
â”‚  - Etcd (metadata)                      â”‚
â”‚  - MinIO (S3 storage)                   â”‚
â”‚  - Milvius Core (search)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ Configurazione

Modifica `.env.example` per customizzare:

```bash
# Database
MILVIUS_HOST=milvius
MILVIUS_PORT=19530

# Backend
LLM_MODEL=mistral          # mistral, llama2, neural-chat, etc
EMBEDDING_MODEL=all-MiniLM-L6-v2
CUDA_VISIBLE_DEVICES=0     # GPU ID

# Frontend
BACKEND_URL=http://backend:8000
```

---

## ğŸ§ª Test Post-Installazione

```bash
# 1. Verifica Backend
curl http://localhost:8000/health
# Deve ritornare: {"status":"healthy",...}

# 2. Accedi a Frontend
open http://localhost:3000

# 3. Upload documento di test
# Trascina un PDF

# 4. Poni una domanda
# "Qual Ã¨ il contenuto principale di questo documento?"

# 5. Verifica risposta
# Deve avere fonte + risposta
```

---

## ğŸ“ Workflow Tipico

```
1. Upload PDF/Documento
   â†“
   PaddleOCR estrae testo
   â†“
   Text splitter (chunks)
   â†“
   Sentence-Transformers genera embeddings
   â†“
   Milvius indicizza vettori

2. Query Utente
   â†“
   Query embedding (Sentence-Transformers)
   â†“
   Search in Milvius (top-k retrieval)
   â†“
   Build context da documenti
   â†“
   LLM genera risposta (Ollama)
   â†“
   Return answer + sources
```

---

## ğŸ› ï¸ Performance Tuning

### Se Ã¨ lento:

1. **OCR lento** â†’ Dedica GPU: `CUDA_VISIBLE_DEVICES=0`
2. **Embedding lento** â†’ Aumenta batch: `EMBEDDING_BATCH_SIZE=64`
3. **LLM lento** â†’ Usa modello piccolo: `LLM_MODEL=neural-chat-7b`
4. **Sistema lento** â†’ Aumenta RAM o riduci batch size

### Se VRAM is low:

```bash
# Quantize LLM (4-bit)
OLLAMA_LOAD_TIMEOUT=300s

# Reduce embedding batch
EMBEDDING_BATCH_SIZE=16
```

---

## ğŸ” Sicurezza

âœ… **Codice protetto** dentro container Docker
âœ… **Network isolato** tra servizi
âœ… **No source visible** nel deploy
âœ… **Offuscamento disponibile** con PyArmor (su richiesta)
âœ… **Backend non esposto** pubblicamente

---

## ğŸ“ Support & Troubleshooting

### Backend non risponde?
```bash
docker-compose logs backend
docker-compose restart backend
```

### Milvius connection error?
```bash
# Verifica connection
telnet localhost 19530

# Restart Milvius
docker-compose restart milvius
```

### GPU non riconosciuta?
```bash
# Test GPU
docker run --rm --gpus all nvidia/cuda nvidia-smi

# Riavvia Docker daemon
sudo systemctl restart docker
```

### Out of Memory?
```bash
# Reduce batch sizes in .env
EMBEDDING_BATCH_SIZE=16
LLM_MODEL=neural-chat-7b
```

---

## ğŸ“š Documentazione Completa

**Inside rag-enterprise-structure/**:

- `README.md` - Architettura dettagliata
- `QUICKSTART.md` - Setup per diversi scenari
- `backend/app.py` - API endpoints documentati
- `backend/Dockerfile` - Build configuration

---

## âœ… Checklist Pre-Produzione

- [ ] Hardware verificato (GPU, RAM, SSD)
- [ ] Docker + NVIDIA Docker installati
- [ ] Setup script eseguito senza errori
- [ ] Health check passato
- [ ] Test document upload completato
- [ ] Test query completato
- [ ] Performance accettabile
- [ ] Backup procedure documentata
- [ ] Firewall rules configurati
- [ ] Cliente briefed su funzionamento

---

## ğŸ‰ Next Steps

1. **Leggi STRUCTURE_OVERVIEW.txt** per capire cosa c'Ã¨
2. **Esegui ./setup.sh** per installare
3. **Testa il sistema** con documento di prova
4. **Customizza .env** per tuoi settings
5. **Leggi STACK_FINALE.md** per dettagli tecnici
6. **Contattami** per domande/problemi

---

## ğŸ’¡ Quick Tips

```bash
# Aggiorna modello LLM
docker exec rag-ollama ollama pull mistral

# Visualizza status servizi
docker-compose ps

# Backup Milvius data
docker-compose exec milvius tar -czf /tmp/backup.tar.gz /var/lib/milvius

# Pulisci cache
docker-compose exec backend rm -rf /app/uploads/*
docker system prune -a

# Mostra API docs
open http://localhost:8000/docs
```

---

## ğŸš€ Ready to Go!

Sei pronto per:
- âœ… Deploy locale
- âœ… Deploy distribuito
- âœ… Deploy multi-location
- âœ… Deploy enterprise con HA

**Buona fortuna! ğŸ‰**

---

**Version**: 1.0.0 RAG Enterprise  
**Date**: October 2025  
**Support**: Internal documentation  

